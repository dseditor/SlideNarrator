"""
Breeze2-VITS ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - å–®èªªè©±äººç‰ˆæœ¬
å°ˆç‚ºå°ç£åœ‹èªå„ªåŒ–çš„é«˜å“è³ªèªéŸ³åˆæˆç³»çµ±
"""

import gradio as gr
import numpy as np
import os
import tempfile
import shutil
from pathlib import Path
import torch

try:
    import sherpa_onnx
except ImportError:
    os.system("pip install sherpa-onnx")
    import sherpa_onnx

try:
    from huggingface_hub import hf_hub_download
except ImportError:
    os.system("pip install huggingface_hub")
    from huggingface_hub import hf_hub_download


class TaiwaneseVITSTTS:
    def __init__(self):
        self.tts = None
        self.model_dir = Path("./models")
        self.dict_dir = Path("./dict")
        self.setup_jieba_dict()
        self.setup_model()
    
    def setup_jieba_dict(self):
        """è¨­ç½® jieba å­—å…¸ç›®éŒ„"""
        try:
            print("ğŸ”§ è¨­ç½® jieba å­—å…¸...")
            
            # å‰µå»ºå­—å…¸ç›®éŒ„
            self.dict_dir.mkdir(exist_ok=True)
            
            # å‰µå»ºåŸºæœ¬çš„å­—å…¸æ–‡ä»¶
            self.create_basic_jieba_dict()
            
            print(f"âœ… jieba å­—å…¸è¨­ç½®å®Œæˆ: {self.dict_dir}")
            
        except Exception as e:
            print(f"âš ï¸ jieba å­—å…¸è¨­ç½®å¤±æ•—: {e}")
            # å‰µå»ºç©ºç›®éŒ„ä½œç‚ºå¾Œå‚™
            self.dict_dir.mkdir(exist_ok=True)
    
    def create_basic_jieba_dict(self):
        """å‰µå»ºåŸºæœ¬çš„ jieba å­—å…¸æ–‡ä»¶"""
        try:
            # å‰µå»ºåŸºæœ¬çš„ jieba å­—å…¸æ–‡ä»¶
            jieba_dict_path = self.dict_dir / "jieba.dict.utf8"
            user_dict_path = self.dict_dir / "user.dict.utf8"
            idf_path = self.dict_dir / "idf.txt.big"
            stop_words_path = self.dict_dir / "stop_words.txt"
            
            # å¦‚æœå­—å…¸æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰µå»ºç©ºæ–‡ä»¶
            for file_path in [jieba_dict_path, user_dict_path, idf_path, stop_words_path]:
                if not file_path.exists():
                    file_path.touch()
                    print(f"ğŸ“ å‰µå»ºå­—å…¸æ–‡ä»¶: {file_path.name}")
                
        except Exception as e:
            print(f"âš ï¸ å‰µå»ºåŸºæœ¬å­—å…¸æ–‡ä»¶å¤±æ•—: {e}")

    def verify_model_files(self):
        """æª¢æŸ¥æœ¬åœ°æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_files = ["breeze2-vits.onnx", "lexicon.txt", "tokens.txt"]
        
        missing_files = []
        for file_name in required_files:
            file_path = self.model_dir / file_name
            if not file_path.exists():
                missing_files.append(file_name)
            elif file_path.stat().st_size == 0:
                missing_files.append(f"{file_name} (æª”æ¡ˆå¤§å°ç‚º 0)")
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {missing_files}")
            return False
        
        print("âœ… æ‰€æœ‰æ¨¡å‹æ–‡ä»¶éƒ½å­˜åœ¨")
        for file_name in required_files:
            file_path = self.model_dir / file_name
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"  ğŸ“„ {file_name}: {size_mb:.1f} MB")
        
        return True

    def setup_model(self):
        """è¨­ç½®å’Œåˆå§‹åŒ–æ¨¡å‹"""
        try:
            if not self.verify_model_files():
                raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ç¼ºå¤±")
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            provider = "cuda" if device == "cuda" else "cpu"
            
            print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device.upper()}")
            if device == "cuda":
                try:
                    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
                    print(f"ğŸ’¾ GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
                except:
                    print("ğŸ® GPU è³‡è¨Šç²å–å¤±æ•—ï¼Œä½†å°‡å˜—è©¦ä½¿ç”¨ GPU")
            
            # é…ç½® VITS æ¨¡å‹
            vits_config = sherpa_onnx.OfflineTtsVitsModelConfig(
                model=str(self.model_dir / "breeze2-vits.onnx"),
                lexicon=str(self.model_dir / "lexicon.txt"),
                tokens=str(self.model_dir / "tokens.txt"),
                dict_dir=str(self.dict_dir),
            )
            
            print(f"ğŸ“š å­—å…¸ç›®éŒ„: {self.dict_dir}")
            
            # é…ç½® TTS æ¨¡å‹
            model_config = sherpa_onnx.OfflineTtsModelConfig(
                vits=vits_config,
                num_threads=2 if device == "cpu" else 1,
                debug=False,  # é—œé–‰èª¿è©¦æ¨¡å¼ä»¥æ¸›å°‘æ—¥èªŒ
                provider=provider,
            )
            
            # å‰µå»º TTS é…ç½®
            config = sherpa_onnx.OfflineTtsConfig(
                model=model_config,
                rule_fsts="",
                max_num_sentences=2,  # æ”¯æ´è¼ƒé•·å¥å­
            )
            
            print("ğŸ”„ æ­£åœ¨è¼‰å…¥ TTS æ¨¡å‹...")
            self.tts = sherpa_onnx.OfflineTts(config)
            
            print("ğŸš€ TTS æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ!")
            
            # æ¸¬è©¦æ¨¡å‹
            print("ğŸ§ª é€²è¡Œæ¨¡å‹æ¸¬è©¦...")
            test_audio = self.tts.generate(text="æ¸¬è©¦", sid=0, speed=1.0)
            if len(test_audio.samples) > 0:
                print("âœ… æ¨¡å‹æ¸¬è©¦é€šé!")
            else:
                print("âš ï¸ æ¨¡å‹æ¸¬è©¦å¤±æ•—ï¼Œä½†æ¨¡å‹å·²è¼‰å…¥")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¨­ç½®å¤±æ•—: {e}")
            print(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
            import traceback
            print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            raise

    def synthesize(self, text, speed=1.0):
        """åˆæˆèªéŸ³ - å–®èªªè©±äººç‰ˆæœ¬"""
        if not text or not text.strip():
            return None, "âŒ è«‹è¼¸å…¥æ–‡æœ¬"
        
        # æ–‡æœ¬é è™•ç†
        text = text.strip()
        if len(text) > 500:  # å¢åŠ æ–‡æœ¬é•·åº¦é™åˆ¶
            text = text[:500]
            
        try:
            print(f"ğŸ¤ æ­£åœ¨åˆæˆèªéŸ³: {text[:50]}...")
            print(f"âš¡ èªéŸ³é€Ÿåº¦: {speed}x")
            
            # ç”ŸæˆèªéŸ³ - å›ºå®šä½¿ç”¨èªªè©±äºº ID 0
            audio = self.tts.generate(
                text=text,
                sid=0,  # å›ºå®šä½¿ç”¨ç¬¬ä¸€å€‹èªªè©±äºº
                speed=speed
            )
            
            # ç²å–éŸ³é »æ•¸æ“š
            samples = audio.samples
            sample_rate = audio.sample_rate
            
            if len(samples) == 0:
                return None, "âŒ èªéŸ³ç”Ÿæˆå¤±æ•—ï¼šç”Ÿæˆçš„éŸ³é »ç‚ºç©º"
            
            # è½‰æ›ç‚º numpy é™£åˆ—
            audio_array = np.array(samples, dtype=np.float32)
            
            # ç¢ºä¿æ˜¯å–®è²é“
            if len(audio_array.shape) > 1:
                audio_array = audio_array.mean(axis=1)
            
            # æ­£è¦åŒ–éŸ³é »
            max_val = np.max(np.abs(audio_array))
            if max_val > 0:
                audio_array = audio_array / max_val * 0.9
            
            duration = len(audio_array) / sample_rate
            print(f"âœ… èªéŸ³åˆæˆå®Œæˆ! é•·åº¦: {duration:.2f}ç§’")
            
            return (sample_rate, audio_array), f"âœ… èªéŸ³åˆæˆæˆåŠŸï¼\nğŸ“Š æ¡æ¨£ç‡: {sample_rate}Hz\nâ±ï¸ æ™‚é•·: {duration:.2f}ç§’\nğŸ­ å°ç£åœ‹èªè²éŸ³"
            
        except Exception as e:
            error_msg = f"âŒ èªéŸ³åˆæˆå¤±æ•—: {str(e)}"
            print(error_msg)
            return None, error_msg


# å…¨å±€ TTS å¯¦ä¾‹
print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TTS æ¨¡å‹...")
try:
    tts_model = TaiwaneseVITSTTS()
    print("âœ… TTS ç³»çµ±å°±ç·’!")
    model_status = "ğŸŸ¢ æ¨¡å‹å·²è¼‰å…¥"
except Exception as e:
    print(f"âŒ TTS åˆå§‹åŒ–å¤±æ•—: {e}")
    tts_model = None
    model_status = f"ğŸ”´ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"


def generate_speech(text, speed):
    """Gradio ä»‹é¢å‡½æ•¸ - ç§»é™¤èªªè©±äººåƒæ•¸"""
    if tts_model is None:
        return None, f"âŒ TTS æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥\n\nè©³æƒ…: {model_status}"
    
    return tts_model.synthesize(text, speed)


def create_interface():
    # é è¨­ç¯„ä¾‹æ–‡æœ¬ - ç§»é™¤èªªè©±äººåƒæ•¸
    examples = [
        ["ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆç³»çµ±ï¼", 1.0],
        ["ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé©åˆå‡ºå»èµ°èµ°ã€‚", 1.0],
        ["äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œç‚ºæˆ‘å€‘çš„ç”Ÿæ´»å¸¶ä¾†è¨±å¤šä¾¿åˆ©ã€‚", 1.1],
        ["å°ç£æ˜¯ä¸€å€‹ç¾éº—çš„å³¶å¶¼ï¼Œæœ‰è‘—è±å¯Œçš„æ–‡åŒ–å’Œç¾é£Ÿã€‚", 0.9],
        ["ç§‘æŠ€æ”¹è®Šç”Ÿæ´»ï¼Œå‰µæ–°å¼•é ˜æœªä¾†ã€‚è®“æˆ‘å€‘ä¸€èµ·æ“æŠ±æ™ºæ…§æ™‚ä»£çš„åˆ°ä¾†ã€‚", 1.2],
        ["æ˜¥å¤©ä¾†äº†ï¼Œæ«»èŠ±ç››é–‹ï¼Œå¾®é¢¨è¼•æ‹‚ï¼ŒçœŸæ˜¯å€‹ç¾å¥½çš„å­£ç¯€ã€‚", 0.8],
    ]
    
    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    device_info = "ğŸ® GPU" if torch.cuda.is_available() else "ğŸ’» CPU"
    
    with gr.Blocks(
        title="ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 900px !important;
            margin: auto !important;
        }
        .status-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }
        .feature-box {
            background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
            color: white;
            padding: 10px 15px;
            border-radius: 8px;
            margin: 10px 0;
            text-align: center;
        }
        """
    ) as demo:
        
        gr.HTML(f"""
        <div class="status-box">
            <h1>ğŸ™ï¸ ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS</h1>
            <p><strong>ç‹€æ…‹:</strong> {model_status} | <strong>è¨­å‚™:</strong> {device_info}</p>
        </div>
        """)
        
        gr.HTML("""
        <div class="feature-box">
            <strong>ğŸ‡¹ğŸ‡¼ å°ˆæ¥­å°ç£åœ‹èª TTS</strong> | ç”± MediaTek é–‹ç™¼ï¼Œå°ˆç‚ºç¹é«”ä¸­æ–‡å„ªåŒ–
        </div>
        """)
        
        if not tts_model:
            gr.Markdown(f"""
            ### âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—
            
            **éŒ¯èª¤è©³æƒ…**: {model_status}
            
            **å¯èƒ½åŸå› **:
            - æ¨¡å‹æ–‡ä»¶ç¼ºå¤±æˆ–æå£
            - jieba å­—å…¸é…ç½®å•é¡Œ
            - è¨˜æ†¶é«”ä¸è¶³
            
            è«‹æª¢æŸ¥æ—¥èªŒç²å–æ›´å¤šè³‡è¨Šã€‚
            """)
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ–‡æœ¬è¼¸å…¥
                text_input = gr.Textbox(
                    label="ğŸ“ è¼¸å…¥æ–‡æœ¬ (æœ€å¤š500å­—)",
                    placeholder="è«‹è¼¸å…¥è¦åˆæˆçš„ç¹é«”ä¸­æ–‡æ–‡æœ¬...",
                    lines=5,
                    max_lines=8,
                    value="ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹èªéŸ³åˆæˆæ¸¬è©¦ã€‚æ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡TTSç³»çµ±ï¼"
                )
                
                # åªä¿ç•™èªéŸ³é€Ÿåº¦æ§åˆ¶
                speed = gr.Slider(
                    label="âš¡ èªéŸ³é€Ÿåº¦",
                    minimum=0.5,
                    maximum=2.0,
                    step=0.1,
                    value=1.0,
                    info="èª¿ç¯€èªéŸ³æ’­æ”¾é€Ÿåº¦ (0.5x æ…¢é€Ÿ â†” 2.0x å¿«é€Ÿ)"
                )
                
                # ç”ŸæˆæŒ‰éˆ•
                generate_btn = gr.Button(
                    "ğŸµ ç”Ÿæˆå°ç£åœ‹èªèªéŸ³",
                    variant="primary",
                    size="lg",
                    interactive=tts_model is not None
                )
        
            with gr.Column(scale=1):
                # éŸ³é »è¼¸å‡º
                audio_output = gr.Audio(
                    label="ğŸ”Š ç”Ÿæˆçš„èªéŸ³",
                    type="numpy",
                    interactive=False,
                    show_download_button=True
                )
                
                # ç‹€æ…‹è¨Šæ¯
                status_msg = gr.Textbox(
                    label="ğŸ“Š ç‹€æ…‹è³‡è¨Š",
                    interactive=False,
                    lines=4,
                    value="æº–å‚™å°±ç·’ï¼Œè«‹è¼¸å…¥æ–‡æœ¬ä¸¦é»æ“Šç”ŸæˆèªéŸ³" if tts_model else f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {model_status}"
                )
        
        # ç¯„ä¾‹
        if tts_model:  # åªæœ‰åœ¨æ¨¡å‹æ­£å¸¸è¼‰å…¥æ™‚æ‰é¡¯ç¤ºç¯„ä¾‹
            gr.Examples(
                examples=examples,
                inputs=[text_input, speed],  # ç§»é™¤èªªè©±äººåƒæ•¸
                outputs=[audio_output, status_msg],
                fn=generate_speech,
                cache_examples=False,
                label="ğŸ“š ç¯„ä¾‹æ–‡æœ¬ (é»æ“Šå³å¯ä½¿ç”¨)"
            )
        
        # ä½¿ç”¨èªªæ˜å’ŒæŠ€è¡“è³‡è¨Š
        with gr.Accordion("ğŸ“‹ ä½¿ç”¨èªªæ˜èˆ‡æŠ€è¡“è³‡è¨Š", open=False):
            gr.Markdown(f"""
            ### ğŸš€ ä½¿ç”¨èªªæ˜
            1. åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥ç¹é«”ä¸­æ–‡æ–‡æœ¬ (æ”¯æ´æœ€å¤š500å­—)
            2. èª¿æ•´èªéŸ³é€Ÿåº¦ (å»ºè­°ç¯„åœ 0.8x - 1.5x)
            3. é»æ“Šã€Œç”Ÿæˆå°ç£åœ‹èªèªéŸ³ã€æŒ‰éˆ•
            4. åœ¨å³å´æ’­æ”¾å’Œä¸‹è¼‰ç”Ÿæˆçš„èªéŸ³
            
            ### ğŸ¯ æ¨¡å‹ç‰¹è‰²
            - **å°ˆæ¥­å°ç£åœ‹èª**: ç¶“éå°ç£èªæ–™è¨“ç·´ï¼Œç™¼éŸ³è‡ªç„¶
            - **é«˜å“è³ªåˆæˆ**: ä½¿ç”¨ VITS æ¶æ§‹ï¼ŒèªéŸ³æ¸…æ™°æµæš¢
            - **ç§»å‹•å„ªåŒ–**: è¼•é‡åŒ–è¨­è¨ˆï¼Œé©åˆå„ç¨®è¨­å‚™
            - **å³æ™‚ç”Ÿæˆ**: å¿«é€Ÿæ¨ç†ï¼Œæ”¯æ´å³æ™‚èªéŸ³åˆæˆ
            
            ### ğŸ”§ æŠ€è¡“è³‡è¨Š
            - **æ¨¡å‹**: MediaTek Breeze2-VITS-onnx
            - **èªè¨€**: ç¹é«”ä¸­æ–‡ (å°ç£åœ‹èª)
            - **æ¡æ¨£ç‡**: 22050 Hz
            - **æ¨ç†å¼•æ“**: Sherpa-ONNX
            - **é‹è¡Œè¨­å‚™**: {device_info}
            - **æ¨¡å‹ç‹€æ…‹**: {model_status}
            - **å­—å…¸é…ç½®**: {'âœ… å·²é…ç½®' if Path('./dict').exists() else 'âŒ æœªé…ç½®'}
            
            ### ğŸ“ æœ€ä½³å¯¦è¸
            - **æ–‡æœ¬é•·åº¦**: å»ºè­°å–®æ¬¡åˆæˆ 10-100 å­—ï¼Œæ•ˆæœæœ€ä½³
            - **æ¨™é»ç¬¦è™Ÿ**: é©ç•¶ä½¿ç”¨é€—è™Ÿå’Œå¥è™Ÿä¾†æ§åˆ¶èªèª¿åœé “
            - **èªéŸ³é€Ÿåº¦**: ä¸€èˆ¬å°è©±å»ºè­° 1.0xï¼Œæœ—è®€å»ºè­° 0.9xï¼Œå¿«é€Ÿæ’­å ±å»ºè­° 1.3x
            - **ç‰¹æ®Šå­—ç¬¦**: é¿å…ä½¿ç”¨éå¤šè‹±æ–‡æˆ–ç‰¹æ®Šç¬¦è™Ÿ
            
            ### ğŸ› ï¸ æ•…éšœæ’é™¤
            å¦‚æœé‡åˆ°å•é¡Œï¼š
            1. æª¢æŸ¥æ–‡æœ¬æ˜¯å¦ç‚ºç¹é«”ä¸­æ–‡
            2. å˜—è©¦è¼ƒçŸ­çš„æ–‡æœ¬ (10-50å­—)
            3. é‡æ–°æ•´ç†é é¢é‡æ–°è¼‰å…¥æ¨¡å‹
            4. æª¢æŸ¥ç€è¦½å™¨æ§åˆ¶å°éŒ¯èª¤è¨Šæ¯
            
            ### ğŸ“„ æˆæ¬Šè³‡è¨Š
            - **æ¨¡å‹**: MediaTek Research é–‹æºæ¨¡å‹
            - **ä½¿ç”¨ç¯„åœ**: ç ”ç©¶å’Œå€‹äººä½¿ç”¨
            - **å•†æ¥­ä½¿ç”¨**: è«‹åƒè€ƒ MediaTek æˆæ¬Šæ¢æ¬¾
            """)
        
        # äº‹ä»¶ç¶å®š - ç§»é™¤èªªè©±äººåƒæ•¸
        generate_btn.click(
            fn=generate_speech,
            inputs=[text_input, speed],
            outputs=[audio_output, status_msg],
            api_name="generate_speech"
        )
        
        # éµç›¤å¿«æ·éµ
        text_input.submit(
            fn=generate_speech,
            inputs=[text_input, speed],
            outputs=[audio_output, status_msg]
        )
    
    return demo


# å•Ÿå‹•æ‡‰ç”¨
if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        show_api=True
    )
