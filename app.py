"""
Breeze2-VITS ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - åŒ…å«æœ¬åœ°æ¨¡å‹æ–‡ä»¶
ä½¿ç”¨é å…ˆä¸‹è¼‰çš„æ¨¡å‹æ–‡ä»¶ï¼Œç„¡éœ€å‹•æ…‹ä¸‹è¼‰
"""

import gradio as gr
import numpy as np
import os
from pathlib import Path
import torch

try:
    import sherpa_onnx
except ImportError:
    os.system("pip install sherpa-onnx")
    import sherpa_onnx


class TaiwaneseVITSTTS:
    def __init__(self):
        self.tts = None
        # æ¨¡å‹æ–‡ä»¶ç›´æ¥æ”¾åœ¨ Space æ ¹ç›®éŒ„çš„ models æ–‡ä»¶å¤¾
        self.model_dir = Path("./models")
        self.setup_model()
    
    def verify_model_files(self):
        """æª¢æŸ¥æœ¬åœ°æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_files = [
            "breeze2-vits.onnx",
            "lexicon.txt", 
            "tokens.txt"
        ]
        
        missing_files = []
        for file_name in required_files:
            file_path = self.model_dir / file_name
            if not file_path.exists():
                missing_files.append(file_name)
            elif file_path.stat().st_size == 0:
                missing_files.append(f"{file_name} (æª”æ¡ˆå¤§å°ç‚º 0)")
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {missing_files}")
            print("ğŸ“‚ ç•¶å‰ç›®éŒ„çµæ§‹:")
            for item in Path(".").rglob("*"):
                print(f"  {item}")
            return False
        
        print("âœ… æ‰€æœ‰æ¨¡å‹æ–‡ä»¶éƒ½å­˜åœ¨")
        for file_name in required_files:
            file_path = self.model_dir / file_name
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"  ğŸ“„ {file_name}: {size_mb:.1f} MB")
        
        return True

    def setup_model(self):
        """è¨­ç½®å’Œåˆå§‹åŒ–æ¨¡å‹"""
        try:
            # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶
            if not self.verify_model_files():
                raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼Œè«‹ç¢ºä¿ models/ ç›®éŒ„åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶")
            
            # æª¢æŸ¥ CUDA å¯ç”¨æ€§
            device = "cuda" if torch.cuda.is_available() else "cpu"
            provider = "cuda" if device == "cuda" else "cpu"
            
            print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device.upper()}")
            if device == "cuda":
                print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
                print(f"ğŸ’¾ GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
            
            # é…ç½® VITS æ¨¡å‹
            vits_config = sherpa_onnx.OfflineTtsVitsModelConfig(
                model=str(self.model_dir / "breeze2-vits.onnx"),
                lexicon=str(self.model_dir / "lexicon.txt"),
                tokens=str(self.model_dir / "tokens.txt"),
            )
            
            # é…ç½® TTS æ¨¡å‹
            model_config = sherpa_onnx.OfflineTtsModelConfig(
                vits=vits_config,
                num_threads=4 if device == "cpu" else 1,  # CPU ä½¿ç”¨å¤šç·šç¨‹ï¼ŒGPU ä½¿ç”¨å–®ç·šç¨‹
                debug=False,
                provider=provider,
            )
            
            # å‰µå»º TTS é…ç½®
            config = sherpa_onnx.OfflineTtsConfig(
                model=model_config,
                rule_fsts="",
                max_num_sentences=2,  # æ”¯æ´è¼ƒé•·æ–‡æœ¬
            )
            
            # åˆå§‹åŒ– TTS
            print("ğŸ”„ æ­£åœ¨è¼‰å…¥ TTS æ¨¡å‹...")
            self.tts = sherpa_onnx.OfflineTts(config)
            
            print("ğŸš€ TTS æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ!")
            
            # æ¸¬è©¦æ¨¡å‹
            print("ğŸ§ª é€²è¡Œæ¨¡å‹æ¸¬è©¦...")
            test_audio = self.tts.generate(text="æ¸¬è©¦", sid=0, speed=1.0)
            if len(test_audio.samples) > 0:
                print("âœ… æ¨¡å‹æ¸¬è©¦é€šé!")
            else:
                print("âš ï¸  æ¨¡å‹æ¸¬è©¦å¤±æ•—ï¼Œä½†æ¨¡å‹å·²è¼‰å…¥")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¨­ç½®å¤±æ•—: {e}")
            raise

    def synthesize(self, text, speaker_id=0, speed=1.0):
        """åˆæˆèªéŸ³"""
        if not text or not text.strip():
            return None, "âŒ è«‹è¼¸å…¥æ–‡æœ¬"
        
        # æ–‡æœ¬é è™•ç†
        text = text.strip()
        if len(text) > 200:
            text = text[:200]  # é™åˆ¶æ–‡æœ¬é•·åº¦
            
        try:
            print(f"ğŸ¤ æ­£åœ¨åˆæˆèªéŸ³: {text[:30]}...")
            print(f"ğŸ­ èªªè©±äºº: {speaker_id}, âš¡ é€Ÿåº¦: {speed}x")
            
            # ç”ŸæˆèªéŸ³
            audio = self.tts.generate(
                text=text,
                sid=speaker_id,
                speed=speed
            )
            
            # ç²å–éŸ³é »æ•¸æ“š
            samples = audio.samples
            sample_rate = audio.sample_rate
            
            if len(samples) == 0:
                return None, "âŒ èªéŸ³ç”Ÿæˆå¤±æ•—ï¼šç”Ÿæˆçš„éŸ³é »ç‚ºç©º"
            
            # è½‰æ›ç‚º numpy é™£åˆ—
            audio_array = np.array(samples, dtype=np.float32)
            
            # ç¢ºä¿æ˜¯å–®è²é“
            if len(audio_array.shape) > 1:
                audio_array = audio_array.mean(axis=1)
            
            # æ­£è¦åŒ–éŸ³é » (æ›´ä¿å®ˆçš„æ­£è¦åŒ–)
            max_val = np.max(np.abs(audio_array))
            if max_val > 0:
                audio_array = audio_array / max_val * 0.9  # é¿å…å‰Šæ³¢
            
            duration = len(audio_array) / sample_rate
            print(f"âœ… èªéŸ³åˆæˆå®Œæˆ! é•·åº¦: {duration:.2f}ç§’")
            
            return (sample_rate, audio_array), f"âœ… èªéŸ³åˆæˆæˆåŠŸï¼\nğŸ“Š æ¡æ¨£ç‡: {sample_rate}Hz\nâ±ï¸  æ™‚é•·: {duration:.2f}ç§’\nğŸ­ èªªè©±äºº: {speaker_id}"
            
        except Exception as e:
            error_msg = f"âŒ èªéŸ³åˆæˆå¤±æ•—: {str(e)}"
            print(error_msg)
            return None, error_msg


# å…¨å±€ TTS å¯¦ä¾‹
print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TTS æ¨¡å‹...")
try:
    tts_model = TaiwaneseVITSTTS()
    print("âœ… TTS ç³»çµ±å°±ç·’!")
except Exception as e:
    print(f"âŒ TTS åˆå§‹åŒ–å¤±æ•—: {e}")
    tts_model = None


def generate_speech(text, speaker_id, speed):
    """Gradio ä»‹é¢å‡½æ•¸"""
    if tts_model is None:
        return None, "âŒ TTS æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥"
    
    return tts_model.synthesize(text, speaker_id, speed)


def create_interface():
    # é è¨­ç¯„ä¾‹æ–‡æœ¬
    examples = [
        ["ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆç³»çµ±ï¼", 0, 1.0],
        ["ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé©åˆå‡ºå»èµ°èµ°ã€‚", 1, 1.0],
        ["äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œç‚ºæˆ‘å€‘çš„ç”Ÿæ´»å¸¶ä¾†è¨±å¤šä¾¿åˆ©ã€‚", 2, 1.2],
        ["å°ç£æ˜¯ä¸€å€‹ç¾éº—çš„å³¶å¶¼ï¼Œæœ‰è‘—è±å¯Œçš„æ–‡åŒ–å’Œç¾é£Ÿã€‚", 3, 0.9],
        ["ç§‘æŠ€æ”¹è®Šç”Ÿæ´»ï¼Œå‰µæ–°å¼•é ˜æœªä¾†ã€‚è®“æˆ‘å€‘ä¸€èµ·æ“æŠ±æ™ºæ…§æ™‚ä»£çš„åˆ°ä¾†ã€‚", 4, 1.1],
        ["æ˜¥å¤©ä¾†äº†ï¼Œæ«»èŠ±ç››é–‹ï¼Œå¾®é¢¨è¼•æ‹‚ï¼ŒçœŸæ˜¯å€‹ç¾å¥½çš„å­£ç¯€ã€‚", 5, 0.8],
    ]
    
    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    model_status = "ğŸŸ¢ æ¨¡å‹å·²è¼‰å…¥" if tts_model else "ğŸ”´ æ¨¡å‹è¼‰å…¥å¤±æ•—"
    device_info = "ğŸ® GPU" if torch.cuda.is_available() else "ğŸ’» CPU"
    
    with gr.Blocks(
        title="ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 900px !important;
            margin: auto !important;
        }
        .status-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }
        """
    ) as demo:
        
        gr.HTML(f"""
        <div class="status-box">
            <h1>ğŸ™ï¸ ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS</h1>
            <p><strong>ç‹€æ…‹:</strong> {model_status} | <strong>è¨­å‚™:</strong> {device_info}</p>
        </div>
        """)
        
        gr.Markdown("""
        ä½¿ç”¨ **MediaTek Breeze2-VITS** æ¨¡å‹é€²è¡Œé«˜å“è³ªç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ
        
        âœ¨ **ç‰¹è‰²:** ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å„ªåŒ– | ğŸ­ å¤šç¨®èªªè©±äºº | âš¡ å¿«é€Ÿæ¨ç† | ğŸšï¸ é€Ÿåº¦èª¿ç¯€
        """)
        
        if not tts_model:
            gr.Warning("âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦æ­£ç¢ºæ”¾ç½®")
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ–‡æœ¬è¼¸å…¥
                text_input = gr.Textbox(
                    label="ğŸ“ è¼¸å…¥æ–‡æœ¬ (æœ€å¤š200å­—)",
                    placeholder="è«‹è¼¸å…¥è¦åˆæˆçš„ç¹é«”ä¸­æ–‡æ–‡æœ¬...",
                    lines=4,
                    max_lines=6,
                    value="ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹èªéŸ³åˆæˆæ¸¬è©¦ã€‚æ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡TTSç³»çµ±ï¼"
                )
                
                with gr.Row():
                    # èªªè©±äººé¸æ“‡
                    speaker_id = gr.Slider(
                        label="ğŸ­ èªªè©±äºº",
                        minimum=0,
                        maximum=10,
                        step=1,
                        value=0,
                        info="é¸æ“‡ä¸åŒçš„èªªè©±äººè²éŸ³ (0-10)"
                    )
                    
                    # èªéŸ³é€Ÿåº¦
                    speed = gr.Slider(
                        label="âš¡ èªéŸ³é€Ÿåº¦",
                        minimum=0.5,
                        maximum=2.0,
                        step=0.1,
                        value=1.0,
                        info="èª¿ç¯€èªéŸ³æ’­æ”¾é€Ÿåº¦"
                    )
                
                # ç”ŸæˆæŒ‰éˆ•
                generate_btn = gr.Button(
                    "ğŸµ ç”ŸæˆèªéŸ³",
                    variant="primary",
                    size="lg",
                    interactive=tts_model is not None
                )
        
            with gr.Column(scale=1):
                # éŸ³é »è¼¸å‡º
                audio_output = gr.Audio(
                    label="ğŸ”Š ç”Ÿæˆçš„èªéŸ³",
                    type="numpy",
                    interactive=False,
                    show_download_button=True
                )
                
                # ç‹€æ…‹è¨Šæ¯
                status_msg = gr.Textbox(
                    label="ğŸ“Š ç‹€æ…‹è³‡è¨Š",
                    interactive=False,
                    lines=3,
                    value="æº–å‚™å°±ç·’ï¼Œè«‹è¼¸å…¥æ–‡æœ¬ä¸¦é»æ“Šç”ŸæˆèªéŸ³" if tts_model else "æ¨¡å‹è¼‰å…¥å¤±æ•—"
                )
        
        # ç¯„ä¾‹
        gr.Examples(
            examples=examples,
            inputs=[text_input, speaker_id, speed],
            outputs=[audio_output, status_msg],
            fn=generate_speech,
            cache_examples=False,  # ä¸å¿«å–ç¯„ä¾‹ä»¥ç¯€çœç©ºé–“
            label="ğŸ“š ç¯„ä¾‹æ–‡æœ¬ (é»æ“Šå³å¯ä½¿ç”¨)"
        )
        
        # ä½¿ç”¨èªªæ˜å’ŒæŠ€è¡“è³‡è¨Š
        with gr.Accordion("ğŸ“‹ ä½¿ç”¨èªªæ˜èˆ‡æŠ€è¡“è³‡è¨Š", open=False):
            gr.Markdown(f"""
            ### ä½¿ç”¨èªªæ˜
            1. åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥ç¹é«”ä¸­æ–‡æ–‡æœ¬ (å»ºè­°ä¸è¶…é200å­—)
            2. é¸æ“‡å–œæ­¡çš„èªªè©±äººè²éŸ³ (0-10ï¼Œæ¯å€‹æ•¸å­—å°æ‡‰ä¸åŒè²éŸ³ç‰¹è‰²)
            3. èª¿æ•´èªéŸ³é€Ÿåº¦ (0.5x æ…¢é€Ÿ â†” 2.0x å¿«é€Ÿ)
            4. é»æ“Šã€Œç”ŸæˆèªéŸ³ã€æŒ‰éˆ•
            5. åœ¨å³å´æ’­æ”¾å’Œä¸‹è¼‰ç”Ÿæˆçš„èªéŸ³
            
            ### æŠ€è¡“è³‡è¨Š
            - **æ¨¡å‹**: MediaTek Breeze2-VITS-onnx
            - **èªè¨€**: ç¹é«”ä¸­æ–‡ (å°ç£åœ‹èª)
            - **æ¡æ¨£ç‡**: 22050 Hz
            - **æ¨ç†å¼•æ“**: Sherpa-ONNX
            - **é‹è¡Œè¨­å‚™**: {device_info}
            - **æ¨¡å‹ç‹€æ…‹**: {model_status}
            
            ### æœ€ä½³å¯¦è¸
            - æ–‡æœ¬é•·åº¦å»ºè­°åœ¨ 10-100 å­—ä¹‹é–“ï¼Œæ•ˆæœæœ€ä½³
            - é¿å…ä½¿ç”¨éå¤šæ¨™é»ç¬¦è™Ÿæˆ–ç‰¹æ®Šå­—ç¬¦
            - ä¸åŒèªªè©±äººæœ‰ä¸åŒçš„è²éŸ³ç‰¹è‰²ï¼Œå¯å¤šå˜—è©¦
            - èªéŸ³é€Ÿåº¦å»ºè­°åœ¨ 0.8-1.5 ä¹‹é–“ï¼Œå¤ªå¿«æˆ–å¤ªæ…¢å¯èƒ½å½±éŸ¿æ¸…æ™°åº¦
            """)
        
        # äº‹ä»¶ç¶å®š
        generate_btn.click(
            fn=generate_speech,
            inputs=[text_input, speaker_id, speed],
            outputs=[audio_output, status_msg],
            api_name="generate_speech"
        )
        
        # éµç›¤å¿«æ·éµ
        text_input.submit(
            fn=generate_speech,
            inputs=[text_input, speaker_id, speed],
            outputs=[audio_output, status_msg]
        )
    
    return demo


# å•Ÿå‹•æ‡‰ç”¨
if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        show_api=True
    )
