"""
Breeze2-VITS ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - ä¿®å¾©ç‰ˆ
æ·»åŠ  jieba å­—å…¸æ”¯æ´ä»¥è§£æ±ºä¸­æ–‡ TTS æ¨¡å‹å•é¡Œ
"""

import gradio as gr
import numpy as np
import os
import tempfile
import shutil
from pathlib import Path
import torch

try:
    import sherpa_onnx
except ImportError:
    os.system("pip install sherpa-onnx")
    import sherpa_onnx

try:
    from huggingface_hub import hf_hub_download
except ImportError:
    os.system("pip install huggingface_hub")
    from huggingface_hub import hf_hub_download


class TaiwaneseVITSTTS:
    def __init__(self):
        self.tts = None
        self.model_dir = Path("./models")
        self.dict_dir = Path("./dict")
        self.setup_jieba_dict()
        self.setup_model()
    
    def setup_jieba_dict(self):
        """è¨­ç½® jieba å­—å…¸ç›®éŒ„"""
        try:
            print("ğŸ”§ è¨­ç½® jieba å­—å…¸...")
            
            # å‰µå»ºå­—å…¸ç›®éŒ„
            self.dict_dir.mkdir(exist_ok=True)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦ä¸‹è¼‰å­—å…¸æ–‡ä»¶
            dict_files_needed = [
                "jieba.dict.utf8",
                "user.dict.utf8", 
                "idf.txt.big",
                "stop_words.txt"
            ]
            
            # å˜—è©¦å¾ Hugging Face ä¸‹è¼‰å­—å…¸æ–‡ä»¶ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
            # æˆ–è€…å‰µå»ºåŸºæœ¬çš„å­—å…¸æ–‡ä»¶
            self.create_basic_jieba_dict()
            
            print(f"âœ… jieba å­—å…¸è¨­ç½®å®Œæˆ: {self.dict_dir}")
            
        except Exception as e:
            print(f"âš ï¸ jieba å­—å…¸è¨­ç½®å¤±æ•—: {e}")
            # å‰µå»ºç©ºç›®éŒ„ä½œç‚ºå¾Œå‚™
            self.dict_dir.mkdir(exist_ok=True)
    
    def create_basic_jieba_dict(self):
        """å‰µå»ºåŸºæœ¬çš„ jieba å­—å…¸æ–‡ä»¶"""
        try:
            # å‰µå»ºåŸºæœ¬çš„ jieba å­—å…¸æ–‡ä»¶
            jieba_dict_path = self.dict_dir / "jieba.dict.utf8"
            user_dict_path = self.dict_dir / "user.dict.utf8"
            idf_path = self.dict_dir / "idf.txt.big"
            stop_words_path = self.dict_dir / "stop_words.txt"
            
            # å¦‚æœå­—å…¸æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå‰µå»ºç©ºæ–‡ä»¶
            if not jieba_dict_path.exists():
                jieba_dict_path.touch()
                print(f"ğŸ“ å‰µå»ºç©ºå­—å…¸æ–‡ä»¶: {jieba_dict_path}")
            
            if not user_dict_path.exists():
                user_dict_path.touch()
                print(f"ğŸ“ å‰µå»ºç”¨æˆ¶å­—å…¸æ–‡ä»¶: {user_dict_path}")
            
            if not idf_path.exists():
                idf_path.touch()
                print(f"ğŸ“ å‰µå»º IDF æ–‡ä»¶: {idf_path}")
                
            if not stop_words_path.exists():
                stop_words_path.touch()
                print(f"ğŸ“ å‰µå»ºåœç”¨è©æ–‡ä»¶: {stop_words_path}")
                
        except Exception as e:
            print(f"âš ï¸ å‰µå»ºåŸºæœ¬å­—å…¸æ–‡ä»¶å¤±æ•—: {e}")

    def verify_model_files(self):
        """æª¢æŸ¥æœ¬åœ°æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
        required_files = ["breeze2-vits.onnx", "lexicon.txt", "tokens.txt"]
        
        missing_files = []
        for file_name in required_files:
            file_path = self.model_dir / file_name
            if not file_path.exists():
                missing_files.append(file_name)
            elif file_path.stat().st_size == 0:
                missing_files.append(f"{file_name} (æª”æ¡ˆå¤§å°ç‚º 0)")
        
        if missing_files:
            print(f"âŒ ç¼ºå°‘æ¨¡å‹æ–‡ä»¶: {missing_files}")
            print("ğŸ“‚ ç•¶å‰ç›®éŒ„çµæ§‹:")
            for item in Path(".").rglob("*"):
                if item.is_file():
                    size = item.stat().st_size
                    print(f"  {item}: {size} bytes")
            return False
        
        print("âœ… æ‰€æœ‰æ¨¡å‹æ–‡ä»¶éƒ½å­˜åœ¨")
        for file_name in required_files:
            file_path = self.model_dir / file_name
            size_mb = file_path.stat().st_size / (1024 * 1024)
            print(f"  ğŸ“„ {file_name}: {size_mb:.1f} MB")
        
        return True

    def setup_model(self):
        """è¨­ç½®å’Œåˆå§‹åŒ–æ¨¡å‹"""
        try:
            if not self.verify_model_files():
                raise FileNotFoundError("æ¨¡å‹æ–‡ä»¶ç¼ºå¤±")
            
            device = "cuda" if torch.cuda.is_available() else "cpu"
            provider = "cuda" if device == "cuda" else "cpu"
            
            print(f"ğŸ”§ ä½¿ç”¨è¨­å‚™: {device.upper()}")
            if device == "cuda":
                try:
                    print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
                    print(f"ğŸ’¾ GPU è¨˜æ†¶é«”: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
                except:
                    print("ğŸ® GPU è³‡è¨Šç²å–å¤±æ•—ï¼Œä½†å°‡å˜—è©¦ä½¿ç”¨ GPU")
            
            # é…ç½® VITS æ¨¡å‹ - é—œéµä¿®æ”¹ï¼šæ·»åŠ å­—å…¸ç›®éŒ„
            vits_config = sherpa_onnx.OfflineTtsVitsModelConfig(
                model=str(self.model_dir / "breeze2-vits.onnx"),
                lexicon=str(self.model_dir / "lexicon.txt"),
                tokens=str(self.model_dir / "tokens.txt"),
                dict_dir=str(self.dict_dir),  # æ·»åŠ å­—å…¸ç›®éŒ„
            )
            
            print(f"ğŸ“š å­—å…¸ç›®éŒ„: {self.dict_dir}")
            print(f"ğŸ“ å­—å…¸ç›®éŒ„å…§å®¹: {list(self.dict_dir.iterdir()) if self.dict_dir.exists() else 'ç›®éŒ„ä¸å­˜åœ¨'}")
            
            # é…ç½® TTS æ¨¡å‹
            model_config = sherpa_onnx.OfflineTtsModelConfig(
                vits=vits_config,
                num_threads=2 if device == "cpu" else 1,
                debug=True,  # å•Ÿç”¨èª¿è©¦æ¨¡å¼ä»¥ç²å¾—æ›´å¤šè³‡è¨Š
                provider=provider,
            )
            
            # å‰µå»º TTS é…ç½®
            config = sherpa_onnx.OfflineTtsConfig(
                model=model_config,
                rule_fsts="",
                max_num_sentences=1,
            )
            
            print("ğŸ”„ æ­£åœ¨è¼‰å…¥ TTS æ¨¡å‹...")
            self.tts = sherpa_onnx.OfflineTts(config)
            
            print("ğŸš€ TTS æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ!")
            
            # æ¸¬è©¦æ¨¡å‹
            print("ğŸ§ª é€²è¡Œæ¨¡å‹æ¸¬è©¦...")
            test_audio = self.tts.generate(text="æ¸¬è©¦", sid=0, speed=1.0)
            if len(test_audio.samples) > 0:
                print("âœ… æ¨¡å‹æ¸¬è©¦é€šé!")
            else:
                print("âš ï¸ æ¨¡å‹æ¸¬è©¦å¤±æ•—ï¼Œä½†æ¨¡å‹å·²è¼‰å…¥")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹è¨­ç½®å¤±æ•—: {e}")
            print(f"éŒ¯èª¤é¡å‹: {type(e).__name__}")
            import traceback
            print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            raise

    def synthesize(self, text, speaker_id=0, speed=1.0):
        """åˆæˆèªéŸ³"""
        if not text or not text.strip():
            return None, "âŒ è«‹è¼¸å…¥æ–‡æœ¬"
        
        # æ–‡æœ¬é è™•ç†
        text = text.strip()
        if len(text) > 200:
            text = text[:200]
            
        try:
            print(f"ğŸ¤ æ­£åœ¨åˆæˆèªéŸ³: {text[:30]}...")
            print(f"ğŸ­ èªªè©±äºº: {speaker_id}, âš¡ é€Ÿåº¦: {speed}x")
            
            # ç”ŸæˆèªéŸ³
            audio = self.tts.generate(
                text=text,
                sid=speaker_id,
                speed=speed
            )
            
            # ç²å–éŸ³é »æ•¸æ“š
            samples = audio.samples
            sample_rate = audio.sample_rate
            
            if len(samples) == 0:
                return None, "âŒ èªéŸ³ç”Ÿæˆå¤±æ•—ï¼šç”Ÿæˆçš„éŸ³é »ç‚ºç©º"
            
            # è½‰æ›ç‚º numpy é™£åˆ—
            audio_array = np.array(samples, dtype=np.float32)
            
            # ç¢ºä¿æ˜¯å–®è²é“
            if len(audio_array.shape) > 1:
                audio_array = audio_array.mean(axis=1)
            
            # æ­£è¦åŒ–éŸ³é »
            max_val = np.max(np.abs(audio_array))
            if max_val > 0:
                audio_array = audio_array / max_val * 0.9
            
            duration = len(audio_array) / sample_rate
            print(f"âœ… èªéŸ³åˆæˆå®Œæˆ! é•·åº¦: {duration:.2f}ç§’")
            
            return (sample_rate, audio_array), f"âœ… èªéŸ³åˆæˆæˆåŠŸï¼\nğŸ“Š æ¡æ¨£ç‡: {sample_rate}Hz\nâ±ï¸ æ™‚é•·: {duration:.2f}ç§’\nğŸ­ èªªè©±äºº: {speaker_id}"
            
        except Exception as e:
            error_msg = f"âŒ èªéŸ³åˆæˆå¤±æ•—: {str(e)}"
            print(error_msg)
            import traceback
            print(f"è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
            return None, error_msg


# å…¨å±€ TTS å¯¦ä¾‹
print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– TTS æ¨¡å‹...")
try:
    tts_model = TaiwaneseVITSTTS()
    print("âœ… TTS ç³»çµ±å°±ç·’!")
    model_status = "ğŸŸ¢ æ¨¡å‹å·²è¼‰å…¥"
except Exception as e:
    print(f"âŒ TTS åˆå§‹åŒ–å¤±æ•—: {e}")
    tts_model = None
    model_status = f"ğŸ”´ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}"


def generate_speech(text, speaker_id, speed):
    """Gradio ä»‹é¢å‡½æ•¸"""
    if tts_model is None:
        return None, f"âŒ TTS æ¨¡å‹æœªæ­£ç¢ºè¼‰å…¥\n\nè©³æƒ…: {model_status}"
    
    return tts_model.synthesize(text, speaker_id, speed)


def create_interface():
    # é è¨­ç¯„ä¾‹æ–‡æœ¬
    examples = [
        ["ä½ å¥½ï¼Œæ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆç³»çµ±ï¼", 0, 1.0],
        ["ä»Šå¤©å¤©æ°£å¾ˆå¥½ï¼Œé©åˆå‡ºå»èµ°èµ°ã€‚", 1, 1.0],
        ["äººå·¥æ™ºæ…§æŠ€è¡“æ­£åœ¨å¿«é€Ÿç™¼å±•ï¼Œç‚ºæˆ‘å€‘çš„ç”Ÿæ´»å¸¶ä¾†è¨±å¤šä¾¿åˆ©ã€‚", 2, 1.2],
        ["å°ç£æ˜¯ä¸€å€‹ç¾éº—çš„å³¶å¶¼ï¼Œæœ‰è‘—è±å¯Œçš„æ–‡åŒ–å’Œç¾é£Ÿã€‚", 3, 0.9],
        ["ç§‘æŠ€æ”¹è®Šç”Ÿæ´»ï¼Œå‰µæ–°å¼•é ˜æœªä¾†ã€‚", 4, 1.1],
    ]
    
    # æª¢æŸ¥æ¨¡å‹ç‹€æ…‹
    device_info = "ğŸ® GPU" if torch.cuda.is_available() else "ğŸ’» CPU"
    
    with gr.Blocks(
        title="ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS",
        theme=gr.themes.Soft(),
        css="""
        .gradio-container {
            max-width: 900px !important;
            margin: auto !important;
        }
        .status-box {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 15px;
            border-radius: 10px;
            margin: 10px 0;
        }
        """
    ) as demo:
        
        gr.HTML(f"""
        <div class="status-box">
            <h1>ğŸ™ï¸ ç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ - Breeze2-VITS</h1>
            <p><strong>ç‹€æ…‹:</strong> {model_status} | <strong>è¨­å‚™:</strong> {device_info}</p>
        </div>
        """)
        
        gr.Markdown("""
        ä½¿ç”¨ **MediaTek Breeze2-VITS** æ¨¡å‹é€²è¡Œé«˜å“è³ªç¹é«”ä¸­æ–‡èªéŸ³åˆæˆ
        
        âœ¨ **ç‰¹è‰²:** ğŸ‡¹ğŸ‡¼ ç¹é«”ä¸­æ–‡å„ªåŒ– | ğŸ­ å¤šç¨®èªªè©±äºº | âš¡ å¿«é€Ÿæ¨ç† | ğŸšï¸ é€Ÿåº¦èª¿ç¯€
        """)
        
        if not tts_model:
            gr.Markdown(f"""
            ### âš ï¸ æ¨¡å‹è¼‰å…¥å¤±æ•—
            
            **éŒ¯èª¤è©³æƒ…**: {model_status}
            
            **å¯èƒ½åŸå› **:
            - æ¨¡å‹æ–‡ä»¶ç¼ºå¤±æˆ–æå£
            - jieba å­—å…¸é…ç½®å•é¡Œ
            - è¨˜æ†¶é«”ä¸è¶³
            
            è«‹æª¢æŸ¥æ—¥èªŒç²å–æ›´å¤šè³‡è¨Šã€‚
            """)
        
        with gr.Row():
            with gr.Column(scale=1):
                # æ–‡æœ¬è¼¸å…¥
                text_input = gr.Textbox(
                    label="ğŸ“ è¼¸å…¥æ–‡æœ¬ (æœ€å¤š200å­—)",
                    placeholder="è«‹è¼¸å…¥è¦åˆæˆçš„ç¹é«”ä¸­æ–‡æ–‡æœ¬...",
                    lines=4,
                    max_lines=6,
                    value="ä½ å¥½ï¼Œé€™æ˜¯ä¸€å€‹èªéŸ³åˆæˆæ¸¬è©¦ã€‚æ­¡è¿ä½¿ç”¨ç¹é«”ä¸­æ–‡TTSç³»çµ±ï¼"
                )
                
                with gr.Row():
                    # èªªè©±äººé¸æ“‡
                    speaker_id = gr.Slider(
                        label="ğŸ­ èªªè©±äºº",
                        minimum=0,
                        maximum=10,
                        step=1,
                        value=0,
                        info="é¸æ“‡ä¸åŒçš„èªªè©±äººè²éŸ³ (0-10)"
                    )
                    
                    # èªéŸ³é€Ÿåº¦
                    speed = gr.Slider(
                        label="âš¡ èªéŸ³é€Ÿåº¦",
                        minimum=0.5,
                        maximum=2.0,
                        step=0.1,
                        value=1.0,
                        info="èª¿ç¯€èªéŸ³æ’­æ”¾é€Ÿåº¦"
                    )
                
                # ç”ŸæˆæŒ‰éˆ•
                generate_btn = gr.Button(
                    "ğŸµ ç”ŸæˆèªéŸ³",
                    variant="primary",
                    size="lg",
                    interactive=tts_model is not None
                )
        
            with gr.Column(scale=1):
                # éŸ³é »è¼¸å‡º
                audio_output = gr.Audio(
                    label="ğŸ”Š ç”Ÿæˆçš„èªéŸ³",
                    type="numpy",
                    interactive=False,
                    show_download_button=True
                )
                
                # ç‹€æ…‹è¨Šæ¯
                status_msg = gr.Textbox(
                    label="ğŸ“Š ç‹€æ…‹è³‡è¨Š",
                    interactive=False,
                    lines=4,
                    value="æº–å‚™å°±ç·’ï¼Œè«‹è¼¸å…¥æ–‡æœ¬ä¸¦é»æ“Šç”ŸæˆèªéŸ³" if tts_model else f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {model_status}"
                )
        
        # ç¯„ä¾‹
        if tts_model:  # åªæœ‰åœ¨æ¨¡å‹æ­£å¸¸è¼‰å…¥æ™‚æ‰é¡¯ç¤ºç¯„ä¾‹
            gr.Examples(
                examples=examples,
                inputs=[text_input, speaker_id, speed],
                outputs=[audio_output, status_msg],
                fn=generate_speech,
                cache_examples=False,
                label="ğŸ“š ç¯„ä¾‹æ–‡æœ¬ (é»æ“Šå³å¯ä½¿ç”¨)"
            )
        
        # ä½¿ç”¨èªªæ˜å’ŒæŠ€è¡“è³‡è¨Š
        with gr.Accordion("ğŸ“‹ ä½¿ç”¨èªªæ˜èˆ‡æŠ€è¡“è³‡è¨Š", open=False):
            gr.Markdown(f"""
            ### ä½¿ç”¨èªªæ˜
            1. åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥ç¹é«”ä¸­æ–‡æ–‡æœ¬ (å»ºè­°ä¸è¶…é200å­—)
            2. é¸æ“‡å–œæ­¡çš„èªªè©±äººè²éŸ³ (0-10ï¼Œæ¯å€‹æ•¸å­—å°æ‡‰ä¸åŒè²éŸ³ç‰¹è‰²)
            3. èª¿æ•´èªéŸ³é€Ÿåº¦ (0.5x æ…¢é€Ÿ â†” 2.0x å¿«é€Ÿ)
            4. é»æ“Šã€Œç”ŸæˆèªéŸ³ã€æŒ‰éˆ•
            5. åœ¨å³å´æ’­æ”¾å’Œä¸‹è¼‰ç”Ÿæˆçš„èªéŸ³
            
            ### æŠ€è¡“è³‡è¨Š
            - **æ¨¡å‹**: MediaTek Breeze2-VITS-onnx
            - **èªè¨€**: ç¹é«”ä¸­æ–‡ (å°ç£åœ‹èª)
            - **æ¡æ¨£ç‡**: 22050 Hz
            - **æ¨ç†å¼•æ“**: Sherpa-ONNX
            - **é‹è¡Œè¨­å‚™**: {device_info}
            - **æ¨¡å‹ç‹€æ…‹**: {model_status}
            - **jieba å­—å…¸**: {'âœ… å·²é…ç½®' if Path('./dict').exists() else 'âŒ æœªé…ç½®'}
            
            ### æ•…éšœæ’é™¤
            å¦‚æœé‡åˆ°å•é¡Œï¼š
            1. æª¢æŸ¥æ–‡æœ¬æ˜¯å¦ç‚ºç¹é«”ä¸­æ–‡
            2. å˜—è©¦è¼ƒçŸ­çš„æ–‡æœ¬ (10-50å­—)
            3. é‡æ–°æ•´ç†é é¢
            4. æª¢æŸ¥ç€è¦½å™¨æ§åˆ¶å°éŒ¯èª¤
            """)
        
        # äº‹ä»¶ç¶å®š
        generate_btn.click(
            fn=generate_speech,
            inputs=[text_input, speaker_id, speed],
            outputs=[audio_output, status_msg],
            api_name="generate_speech"
        )
        
        # éµç›¤å¿«æ·éµ
        text_input.submit(
            fn=generate_speech,
            inputs=[text_input, speaker_id, speed],
            outputs=[audio_output, status_msg]
        )
    
    return demo


# å•Ÿå‹•æ‡‰ç”¨
if __name__ == "__main__":
    demo = create_interface()
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        show_api=True
    )
